---
title: Scaling Down Multi-Lingual Code Language Models
summary: Fine-tuning large language models for code generation in different programming languages using PyTorch and HuggingFace Transformers.
tags:
  - Deep Learning
  - Natural Language Processing
  - Code Generation
  - PyTorch
  - HuggingFace
  - LLM
date: '2023-04-27T00:00:00Z'

# Optional external URL for project (replaces project detail page).
external_link: ''

image:
  caption: Screen Shot of the Code Generation with Language-Specific LoRa Models HuggingFace Space
  focal_point: Smart

links:
  - icon: huggingface
    icon_pack: fab
    name: Demo
    url: https://huggingface.co/spaces/ammarnasr/Code-Generation-with-Language-Specific-LoRa-Models
url_code: 'https://github.com/ammarnasr/LLM-for-code-intelligence'
url_pdf: 'https://github.com/ammarnasr/LLM-for-code-intelligence/blob/main/Progress%20Tracking.pdf'
url_slides: ''
url_video: ''

# Slides (optional).
#   Associate this project with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
slides: code-llm
---

Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.

